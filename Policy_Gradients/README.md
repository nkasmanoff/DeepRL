# Policy Gradients

This repo contains a notebook tracking the code used to implement a policy gradient, built heavily off the wonderful tutorial by Machine Learning with Phil at https://www.youtube.com/watch?v=GOBvUA9lK1Q&t. His code works all on it's own, so the topics I am going to build off of for it are mainly the additional types of tools you can add to a vanilla policy gradient. 


These add-ons include a baseline, rewards to go, and discounting factors. 

I'll organize this repo as follows:

Phil.ipynb contains the direct implementation of the tutorial video.

PolicyGradients.ipynb is a fork of that first notebook, but with the various changes noted above and corresponding results they produce in training. 